
# Token与Session的区别是什么？

**1. 存储位置不同**
• **Session**：由服务端生成并存储在服务端内存或持久层（如Redis）中，客户端只保存一个Session ID。
• **Token**：由服务端生成后返回给客户端，客户端（通常是浏览器或App）持有Token并在每次请求中携带，服务端不保存用户状态。


**2. 扩展性和分布式支持**
• **Session**：在分布式系统中需要做Session共享（如使用Redis集中存储Session），否则用户在不同服务器上会频繁登录失效。
• **Token**：天然支持分布式，因为服务端不保存状态，只要能验证Token即可，适合微服务架构。


在我的项目里，session是HttpSession实现，会存储在服务器，但没办法跨服务器使用。所以使用了token解决这个问题。
当你第一次访问 /sendCode 接口时：
1. 浏览器没有 Session ID，Tomcat 自动创建一个新的 Session；
2. 然后通过响应头 Set-Cookie 把 JSESSIONID=xxx 发送到浏览器；
3. 下次请求时，浏览器会自动带上 Cookie: JSESSIONID=xxx；
4. 服务端通过这个 ID 找回之前的 HttpSession 对象，实现会话保


# 讲讲你的Token实现

在用户登录的时候会随机生成Token(UUID)作为登陆令牌，然后把用户数据用Token作为key，存到redis里面。然后把token返回回去
## 对比UUID和雪花算法

| **项目** | **UUID（通用唯一标识符）**               | **雪花算法（Snowflake）**             |
| ------ | ------------------------------- | ------------------------------- |
| 来源     | Java 标准库内置方法（UUID.randomUUID()） | 最早由 Twitter 提出，适用于分布式 ID 生成     |
| 生成方式   | 基于随机数 + 时间戳 + MAC地址等混合生成        | 基于时间戳 + 数据中心ID + 机器ID + 序列号组合生成 |
| 长度     | 128位（二进制），通常是36位字符串             | 64位整数（long 类型）                  |

| **场景**                | **推荐使用**      | **原因**               |
| --------------------- | ------------- | -------------------- |
| 登录 token / session ID | UUID          | 随机性强、不可预测、安全性高       |
| 分布式数据库主键              | 雪花算法          | 数值型、递增、支持顺序插入、高效索引   |
| 订单号 / 交易号             | 雪花算法 + 自定义前缀  | 可以控制长度、时间顺序性，利于排序与排查 |
| 临时身份标识 / 游客 ID        | UUID 或 nanoId | 不要求有序，只要唯一且不可预测即可    |


# 为什么Token要存入Redis？是否可以直接使用Token？

**✅ 1. 直接用 Token 也可以，但不够安全 & 不可控**

最典型的“直接用 token”方案是 **JWT（JSON Web Token）**：

• JWT 把用户信息直接编码进 token（如用户ID、角色、过期时间等）；

• 服务端只需要验证签名和过期时间即可，不用查询 Redis。  

**听起来确实是“无状态”且高效，但问题来了：**

• JWT 一旦发出去，服务端就**无法手动失效**（比如强制下线、注销用户、修改用户权限时）；

• token 泄露后，即使用户已经登出、换密码，别人依然可以拿旧 token 正常请求；

• 过期之前，JWT 就像“失控的门票”，服务端无法干预。

👉 所以 **JWT 适合安全要求不那么高、或只能做短时认证的场景**。

---

**✅ 2. 把 Token 存入 Redis，是为了“可控、安全、可扩展”**

你现在的做法是：

• 登录后生成一个随机 token；

• 把 token 作为 Redis 的 key，用户信息作为 value 存进去；

• 前端每次请求带上 token；

• 服务端从 Redis 拿到对应用户信息，完成认证。


这种方式的优势在于：

**✅ ① 服务端可控（随时注销/强制失效）**

你可以：

• 设置 Redis 过期时间；

• 用户主动登出时删除 token；

• 管理后台强制踢人、限制登录等。

**✅ ② 服务端可以动态续期**

你项目中就做了这一点：
```
stringRedisTemplate.expire(key, LOGIN_USER_TTL, TimeUnit.MINUTES);
```

也就是**每次请求后自动延长登录有效期**，提高用户体验。

**✅ ③ 支持复杂用户模型**
你可以在 Redis 中存储的不止是用户ID，还可以是整个 UserDTO，甚至加上登录设备、权限等级等。

**✅ ④ 安全性更高**

Token 是随机字符串，没有包含用户敏感信息，**即使被盗用也可以通过 Redis 控制其有效性**，更安全。

---

**✅ 3. 总结一句话（面试话术）：**


> 虽然直接用 Token（如 JWT）可以做到无状态认证，但不利于服务端控制、强制失效或续签；而将 Token 存入 Redis 是一种“伪无状态”的设计，结合了高并发支持和服务端可控的优点，特别适合需要高安全性、动态权限控制的业务场景。

---


# 仿大众点评项目的整体技术架构是怎样的？

```sh
前端页面（静态资源）或 Vue 项目
↓
Nginx 网关（可选，统一转发 + 静态资源）
↓
Spring Boot 服务（可多实例部署）
↓
Redis（高可用集群）  +  MySQL（主从 + 索引优化）
↓
Redis Stream / Kafka（消息中间件，异步任务）
```
> 这个仿大众点评项目采用 Spring Boot 架构，结合 Redis 实现了用户认证、缓存优化、分布式锁、异步下单等核心业务能力，配合拦截器 + ThreadLocal 实现无状态登录机制，缓存层支持高并发读写与防击穿、雪崩等问题，整体技术架构清晰、实用，符合现代中后台系统的设计要求




# 秒杀券模块中，Redis的数据结构是如何设计的？

锁的key是Lock+自定义名字（用户id）     value是获取的到的线程（防止误删） 要原子性 用lua脚本

库存信息：String类型 Key：优惠券Id  value：库存值
一人一单：Set类型     Key：优惠券的id   value：用户id

## 具体在Redis中存储了哪些信息

## 库存信息是如何设计和存储的？


# 场景题：当系统面临高QPS（如100万）时，你的设计如何应对？是否需要调整？

我的回答是起多个redis库，把请求分到十个redis库存里，对请求进行分发处理。

# 你的系统会面临热点问题吗？如何处理热点与一致性问题？

异步写入DB，提前缓存好数据




# 什么是动态代理？ 介绍一下动态代理的一些原理类型

# Java的垃圾回收机制（GC）是怎样的

# 不同的一些算法你有没有了解
# ConcurrentHashMap如何实现线程安全？

`ConcurrentHashMap` 取消了 `Segment` 分段锁，采用 `Node + CAS + synchronized` 来保证并发安全。
JDK 1.8 ConcurrentHashMap JDK 1.8 ConcurrentHashMap 主要通过 volatile + CAS 或者 synchronized来实现的线程安全的。添加元素时首先会判断容器是否为空：

- ﻿﻿如果为空则使用 volatile 加 CAS 来初始化
- ﻿如果容器不为空，则根据存储的元素计算该位置是否为空。
- ﻿如果根据存储的元素计算结果为空，则利用CAS 设置该节点；
- ﻿如果根据存储的元素计算结果不为空，则使用 synchronized，然后，遍历桶中的数据，并替换或新增节点到桶中，最后再判断是否需要转为红黑树，这样就能保证并发访问时的线程安全了。

如果把上面的执行用一句话归纳的话，就相当于是ConcurrentHashMap通过对头结点加锁来保证线程安全的，锁的粒度相比 Segment来说更小了，发生冲突和加锁的频率降低了，并发操作的性能就提高了。

而且JDK1.8使用的是红黑树优化了之前的固定链表，那么当数据量比较大的时候，查询性能也得到了很大的提升，从之前的 O（n）优化到了 O（logn）的时间复杂度。

![](https://oss.javaguide.cn/github/javaguide/java/collection/java8_concurrenthashmap.png)




 **✅ 2. 写操作使用 synchronized + CAS 保证局部互斥**

以 put() 为例：

**核心流程如下：**

• 根据 key 计算 hash，定位到桶的位置
• 如果该桶为空，用 **CAS（无锁原子操作）** 插入节点
• 如果该桶不为空（冲突了）：
• 进入 synchronized 加锁，只锁当前桶节点（链表头）
• 遍历链表，插入或替换 value

🔒 **注意：锁粒度是“桶级别”，不会锁整个 Map**，所以多个线程写不同的桶可以并发进行。

---

**✅ 3. 读操作是无锁的（高性能）**
• get() 方法不加锁，直接根据 hash 定位、遍历链表查找
• 利用了 Java 的 **volatile + final + 内存可见性** 来确保读到的是最新值

> 因为写操作用了 CAS + synchronized 插入/更新节点，所以读到的一定是一致的或“即将一致的”，不需要加锁。

---

**✅ 4. 扩容时的线程安全保障**

• 扩容由线程触发，**多个线程可以协作迁移数据**；
• 使用 **forwarding node（占位节点）** 标识迁移状态，避免冲突；
• 避免了 HashMap 扩容中的“链表成环死循环”问题


# TCP协议如何实现可靠传输？涉及哪些机制


# 算法题：一个方法判断一棵二叉树是否是对称的
ACM模式
自己写Class，自己测试


# UML图有哪些
类图: 展示类与类之间的关系
用例图：描述用户（角色）与系统功能的交互关系 
![](https://i-blog.csdnimg.cn/blog_migrate/f6d303a6c6f1615cd416ac87b77d45cc.jpeg)


活动图： 展示一个业务流程、工作流或方法内部的执行步骤，关注“流程控制”与“条件分支”。
![](https://i-blog.csdnimg.cn/blog_migrate/01df941a5dd728e68372ffcf4a7f0b68.png)
状态图：描述某个对象在其生命周期中状态的变化过程，以及事件如何驱动状态转移.
![](https://pic3.zhimg.com/v2-a1bd2ebdc21060b28c867a04d55f802a_1440w.jpg)


时序图：描述系统中多个对象/模块之间的交互顺序，展示“谁调用了谁、什么时候调用、调用了什么”。
![](https://i-blog.csdnimg.cn/blog_migrate/bb21ec68c5ed6c8894645b42d3682781.jpeg)
# SPI机制简单讲一下



# 反射机制了解吗

# PostgreSQL（PG）和MySQL的区别是什么？

PostgreSQL 的特性包括：

- [时间点恢复](https://zhida.zhihu.com/search?content_id=195263833&content_type=Article&match_order=1&q=%E6%97%B6%E9%97%B4%E7%82%B9%E6%81%A2%E5%A4%8D&zhida_source=entity) (PITR) 将数据库还原到特定时间点。
- 使用 pgBackRest 等工具记录对数据库的所有更改的[预写日志](https://zhida.zhihu.com/search?content_id=195263833&content_type=Article&match_order=1&q=%E9%A2%84%E5%86%99%E6%97%A5%E5%BF%97&zhida_source=entity) (WAL)。
- 用于创建和保留自定义子程序的[存储过程。](https://link.zhihu.com/?target=https%3A//www.ibm.com/support/knowledgecenter/en/ssw_ibm_i_74/sqlp/rbafysproeg.htm)


• PG 支持丰富的数据类型（如 JSONB, ARRAY, UUID, HSTORE），还可以自定义操作符、类型、索引方法等。
• MySQL 类型支持相对有限，扩展能力弱。

  


**二、PG 在复杂查询方面表现更好的机制分析**
  

**1. 更强大的查询优化器（Planner）**

PG 拥有模块化的查询优化器，能对复杂 SQL 执行多种优化策略：

• 多种 Join 策略（Nest Loop、Hash Join、Merge Join）

• 成本估算模型基于行数、I/O、CPU 成本等，支持更细致的计划选择

• 支持**并行查询执行**，可在多核 CPU 上加速大查询

  

**2. 支持更复杂的查询表达能力**

• 支持 **WITH（CTE）表达式**、递归查询

• 支持窗口函数（如 RANK(), ROW_NUMBER() 等）

• 支持 FILTER, ROLLUP, GROUPING SETS 等高级聚合能力

• 子查询优化能力更强，如子查询下推、去相关化（de-correlation）

  

**3. 索引机制更灵活多样**

PG 支持多种索引类型：

• B-tree、Hash、GIN（全文索引）、GiST（空间索引）、BRIN（大表优化）

• 支持表达式索引、部分索引、联合索引

• 能直接为 JSONB 字段建立索引，便于结构化与半结构化数据查询

  

**4. 支持并行执行和异步优化机制**

• 查询执行可并行化：如 Parallel Seq Scan, Parallel Hash Join

• 支持物化视图、查询计划缓存（auto-explain、pg_stat_statements）




---

**✅ “拥有强大的查询优化器”**

• **查询优化器（Query Optimizer）** 是数据库在执行 SQL 时的大脑，它负责**分析 SQL 语句的结构和数据特征，选择最优的执行方式**（比如用 Nest Loop、Hash Join、Merge Join 还是并行处理等）。

• PostgreSQL 的优化器非常成熟，能处理复杂的 SQL，如多表 Join、嵌套子查询、窗口函数、CTE（公用表达式）、聚合分析等，**能自动为复杂语句选择最优的执行路径**。

• 举个例子：你写一个多表联查的 SQL，PG 会评估各种执行计划（如先查哪张表、用哪个 Join 算法），选择执行代价最小的那一条路径。

---

**✅ “擅长处理复杂查询和大数据量”**

• **复杂查询**：指结构复杂的 SQL，比如多层嵌套、多个子查询、大量连接、聚合函数、窗口函数等。

• **大数据量**：PostgreSQL 在处理百万、千万、甚至上亿条数据时仍然能保持良好性能，得益于它对索引、多核并行、磁盘 I/O、内存使用的充分调度。

• PG 的并行查询、丰富的索引类型（如 GIN、GiST、BRIN）、查询计划缓存、表达式索引等机制，**让它在数据量大、SQL结构复杂时依然能跑得快、结果准。**
  

# 为什么PG在复杂查询方面表现更好？具体是哪些机制带来的？

见上面